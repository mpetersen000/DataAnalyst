{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze A/B Test Results by Michelle Petersen\n",
    "\n",
    "## Table of Contents\n",
    "- [Introduction](#intro)\n",
    "- [Part I - Probability](#probability)\n",
    "- [Part II - A/B Test](#ab_test)\n",
    "- [Part III - Regression](#regression)\n",
    "\n",
    "<a id='intro'></a>\n",
    "### Introduction\n",
    "\n",
    "The goal of this project is to understand the results of an A/B test run by an e-commerce website. This resuls will help the company understand if they should implement the new page, keep the old page, or perhaps run the experiment longer to make their decision.\n",
    "\n",
    "<a id='probability'></a>\n",
    "#### Part I - Probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "#Set the seed\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>group</th>\n",
       "      <th>landing_page</th>\n",
       "      <th>converted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>851104</td>\n",
       "      <td>2017-01-21 22:11:48.556739</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>804228</td>\n",
       "      <td>2017-01-12 08:01:45.159739</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>661590</td>\n",
       "      <td>2017-01-11 16:55:06.154213</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>853541</td>\n",
       "      <td>2017-01-08 18:28:03.143765</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>864975</td>\n",
       "      <td>2017-01-21 01:52:26.210827</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id                   timestamp      group landing_page  converted\n",
       "0   851104  2017-01-21 22:11:48.556739    control     old_page          0\n",
       "1   804228  2017-01-12 08:01:45.159739    control     old_page          0\n",
       "2   661590  2017-01-11 16:55:06.154213  treatment     new_page          0\n",
       "3   853541  2017-01-08 18:28:03.143765  treatment     new_page          0\n",
       "4   864975  2017-01-21 01:52:26.210827    control     old_page          1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in ab_data.csv \n",
    "df = pd.read_csv('ab_data.csv')\n",
    "\n",
    "# Examine the first five rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 294478 entries, 0 to 294477\n",
      "Data columns (total 5 columns):\n",
      "user_id         294478 non-null int64\n",
      "timestamp       294478 non-null object\n",
      "group           294478 non-null object\n",
      "landing_page    294478 non-null object\n",
      "converted       294478 non-null int64\n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 11.2+ MB\n"
     ]
    }
   ],
   "source": [
    "# Examine size of the dataset\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>converted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>294478.000000</td>\n",
       "      <td>294478.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>787974.124733</td>\n",
       "      <td>0.119659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>91210.823776</td>\n",
       "      <td>0.324563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>630000.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>709032.250000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>787933.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>866911.750000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>945999.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             user_id      converted\n",
       "count  294478.000000  294478.000000\n",
       "mean   787974.124733       0.119659\n",
       "std     91210.823776       0.324563\n",
       "min    630000.000000       0.000000\n",
       "25%    709032.250000       0.000000\n",
       "50%    787933.500000       0.000000\n",
       "75%    866911.750000       0.000000\n",
       "max    945999.000000       1.000000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Examine statistics\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "290584"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Examine number of unique users\n",
    "unique_users = df[\"user_id\"].nunique()\n",
    "unique_users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##### The proportion of users converted:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of converted rows: \n",
      "35237\n",
      "\n",
      "Number of unique converted users: 35173\n",
      "Proportion of unique converted users: 0.12104245244060237\n"
     ]
    }
   ],
   "source": [
    "df_converted = df.query(\"converted == 1\")\n",
    "print(\"Number of converted rows: \\n\" + str(df_converted.count()[0]))\n",
    "print(\"\\nNumber of unique converted users: \" + str(df_converted[\"user_id\"].nunique()))\n",
    "print(\"Proportion of unique converted users: \" + str(df_converted[\"user_id\"].nunique() / unique_users))   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##### The number of times the `new_page` and `treatment` don't line up:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mismatch in control group: \n",
      "1928\n",
      "\n",
      "Mismatch in treatment group: \n",
      "1965\n",
      "\n",
      "Total Mismatch: \n",
      "3893\n"
     ]
    }
   ],
   "source": [
    "df_mismatch1 = df.loc[(df['group'] == 'control') & (df['landing_page'] != 'old_page')]\n",
    "print(\"Mismatch in control group: \\n\" + str(df_mismatch1.count()[0]))\n",
    "df_mismatch2 = df.loc[(df['group'] == 'treatment') & (df['landing_page'] != 'new_page')]\n",
    "print(\"\\nMismatch in treatment group: \\n\" + str(df_mismatch2.count()[0]))\n",
    "print(\"\\nTotal Mismatch: \\n\" + str(df_mismatch1.count()[0] + df_mismatch2.count()[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Rows with missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing values: \n",
      "user_id         0\n",
      "timestamp       0\n",
      "group           0\n",
      "landing_page    0\n",
      "converted       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of missing values: \\n\" + str(df.isnull().sum(axis = 0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create a new dataframe df2 that combines a treatment and control dataframe.   The treatment received the new page and control received the old page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>group</th>\n",
       "      <th>landing_page</th>\n",
       "      <th>converted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>294462</th>\n",
       "      <td>677163</td>\n",
       "      <td>2017-01-03 19:41:51.902148</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294465</th>\n",
       "      <td>925675</td>\n",
       "      <td>2017-01-07 20:38:26.346410</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294468</th>\n",
       "      <td>643562</td>\n",
       "      <td>2017-01-02 19:20:05.460595</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294472</th>\n",
       "      <td>822004</td>\n",
       "      <td>2017-01-04 03:36:46.071379</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294477</th>\n",
       "      <td>715931</td>\n",
       "      <td>2017-01-16 12:40:24.467417</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id                   timestamp      group landing_page  converted\n",
       "294462   677163  2017-01-03 19:41:51.902148  treatment     new_page          0\n",
       "294465   925675  2017-01-07 20:38:26.346410  treatment     new_page          0\n",
       "294468   643562  2017-01-02 19:20:05.460595  treatment     new_page          0\n",
       "294472   822004  2017-01-04 03:36:46.071379  treatment     new_page          0\n",
       "294477   715931  2017-01-16 12:40:24.467417  treatment     new_page          0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_control = df.loc[((df['group'] == 'control') & (df['landing_page'] == 'old_page'))] \n",
    "df_treatment = df.loc[((df['group'] == 'treatment') & (df['landing_page'] == 'new_page'))] \n",
    "df2 = pd.concat([df_control, df_treatment])     \n",
    "df2.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Double Check all of the correct rows were removed - this should be 0\n",
    "df2[((df2['group'] == 'treatment') == (df2['landing_page'] == 'new_page')) == False].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Number of unique user_id's that are in df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "290584"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_df2_users = df2[\"user_id\"].nunique()\n",
    "unique_df2_users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##### Detect if there are duplicate user_id's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicated_df = df2.loc[df2['user_id'].duplicated() == True]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Print duplicate user_id's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      user_id                   timestamp      group landing_page  converted\n",
      "2893   773192  2017-01-14 02:55:59.590927  treatment     new_page          0\n"
     ]
    }
   ],
   "source": [
    "print(duplicated_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Remove **one** of the rows with a duplicate **user_id**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df2.drop_duplicates(subset=['user_id'], keep='last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [user_id, timestamp, group, landing_page, converted]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Test that the duplicate was removed\n",
    "duplicated_df = df2.loc[df2['user_id'].duplicated() == True]\n",
    "print(duplicated_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The probability of an individual converting regardless of the page they receive:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of user conversions: \n",
      "34753\n",
      "\n",
      "Probability of a user conversion: \n",
      "0.11959708724499628\n"
     ]
    }
   ],
   "source": [
    "df_converted = df2.loc[df2['converted'] == 1]\n",
    "print(\"Total number of user conversions: \\n\" + str(df_converted.count()[0]))\n",
    "print(\"\\nProbability of a user conversion: \\n\" + str(df_converted.count()[0] / df2.count()[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Probability of an that an individual was in the `control` group converting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number in control group: 145274\n",
      "Total number converted in the control group: 17489\n",
      "\n",
      "Probability of user conversion in control group: \n",
      "0.1203863045004612\n"
     ]
    }
   ],
   "source": [
    "df_control = df2.loc[(df2['group'] == 'control')]\n",
    "print(\"Total number in control group: \" + str(df_control.count()[0]))\n",
    "df_control_converted = df_control.loc[(df_control['converted'] == 1)]\n",
    "print(\"Total number converted in the control group: \" + str(df_control_converted.count()[0]))\n",
    "prob_conversions_control = df_control_converted.count()[0] / df_control.count()[0]\n",
    "print(\"\\nProbability of user conversion in control group: \\n\" + str(prob_conversions_control))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Probability of an that an individual was in the `treatment` group converting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number in treatment group: 145310\n",
      "Total number converted in the treatment group: 17264\n",
      "\n",
      "Probability of user conversion in treatment group: \n",
      "0.11880806551510564\n"
     ]
    }
   ],
   "source": [
    "df_treatment = df2.loc[(df2['group'] == 'treatment')]\n",
    "print(\"Total number in treatment group: \" + str(df_treatment.count()[0]))\n",
    "df_treatment_converted = df_treatment.loc[(df_treatment['converted'] == 1)]\n",
    "print(\"Total number converted in the treatment group: \" + str(df_treatment_converted.count()[0]))\n",
    "prob_conversions_treatment = df_treatment_converted.count()[0] / df_treatment.count()[0]\n",
    "print(\"\\nProbability of user conversion in treatment group: \\n\" + str(prob_conversions_treatment))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Probability that an individual received the new page:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability of user seeing the new page: \n",
      "0.5000619442226688\n"
     ]
    }
   ],
   "source": [
    "df_new_page = df2.loc[(df2['landing_page'] == 'new_page')]\n",
    "print(\"Probability of user seeing the new page: \\n\" + str(df_new_page.count()[0] / df2.count()[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The difference between the user conversion probability of the two groups is 0.001578 in favor of keeping the old page. Based on the analysis thus far, we fail to reject the null hypothesis.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='ab_test'></a>\n",
    "### Part II - A/B Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I assume  the old page is better, unless the new page proves to be better with a Type I error rate of 5%. \n",
    "\n",
    "My null and alternative hypothesis are:\n",
    "\n",
    "**H0: $p_{new}$ <= $p_{old}$**\n",
    "\n",
    "**H1: $p_{new}$ > $p_{old}$**\n",
    "\n",
    "**The null hypothesis: the new page generates a conversion rate less than or equal to the old page.**\n",
    "\n",
    "**The alternative hypothesis: the new page generates a conversion rate greater than the old page.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Assumptions:` under the null hypothesis, $p_{new}$ and $p_{old}$ both have \"true\" success rates equal to the **converted** success rate regardless of page - that is $p_{new}$ and $p_{old}$ are equal. Furthermore, assume they are equal to the **converted** rate in **ab_data.csv** regardless of the page. <br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Convertion rate** for $p_{new}$ under the null:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11959708724499628"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_new = df2['converted'].mean()\n",
    "p_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  **Convertion rate** for $p_{old}$ under the null:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11959708724499628"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_old = df2['converted'].mean()\n",
    "p_old"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### $n_{new}$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "145310"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_treatment = df2.loc[(df2['group'] == 'treatment')]\n",
    "n_new = df_treatment.count()[0]\n",
    "n_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### $n_{old}$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "145274\n"
     ]
    }
   ],
   "source": [
    "df_control = df2.loc[(df2['group'] == 'control')]\n",
    "n_old = df_control.count()[0]\n",
    "print(n_old)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Simulate $n_{new}$ transactions with a convert rate of $p_{new}$ under the null. Store $n_{new}$ 1's and 0's in dataframe new_page_converted.\n",
    "new_page_converted =  np.random.choice([0,1], n_new, p=(p_new, 1-p_new))\n",
    "new_page_converted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Simulate $n_{old}$ transactions with a convert rate of $p_{old}$ under the null. \n",
    "# Store $n_{old}$ 1's and 0's in old_page_converted.\n",
    "old_page_converted = np.random.choice([0,1], n_old, p=(p_old, 1-p_old))\n",
    "old_page_converted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$p_{new}$ - $p_{old}$ for simulated values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0008280793296222555"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simulated_difference = new_page_converted.mean() - old_page_converted.mean()\n",
    "simulated_difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate 10,000 $p_{new}$ - $p_{old}$ values. Store all 10,000 values in a numpy array called p_diffs.\n",
    "p_diffs = []\n",
    "size = df2.shape[0]\n",
    "\n",
    "for _ in range(10000):\n",
    "    new_page_converted = np.random.choice([0,1], n_new, p=(p_new, 1-p_new))\n",
    "    old_page_converted = np.random.choice([0,1], n_old, p=(p_old, 1-p_old))\n",
    "    p_diffs.append(new_page_converted.mean() - old_page_converted.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Histogram of the p_diffs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#convert to an array\n",
    "p_diffs = np.array(p_diffs)\n",
    "plt.hist(p_diffs);\n",
    "plt.axvline(x=simulated_difference, color=\"red\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proportion of the **p_diffs** are greater than the actual difference observed in **ab_data.csv**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9032"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual_diffs = df2.query('group == \"treatment\"')['converted'].mean() - df2.query('group == \"control\"')['converted'].mean()\n",
    "p_val = (p_diffs > actual_diffs).mean()\n",
    "p_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The p-value is the probability of observing a statistic (or one more extreme in favor of the alternative) if the null hypothesis is true. Given the high value of .907 we fail to reject the null hypothesis of $p_{new}$ <= $p_{old}$. Based on the data, there isn't a difference between the old and new pages that would suggest using the new page.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of conversions for each page, as well as the number of individuals who received each page. `n_old` and `n_new` refer to the number of rows associated with the old page and new pages, respectively.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels as sm\n",
    "from statsmodels import api\n",
    "from scipy.stats import norm\n",
    "\n",
    "old_page = df2.loc[df2['landing_page'] == 'old_page']\n",
    "new_page = df2.loc[df2['landing_page'] == 'new_page']\n",
    "n_old = old_page.count()[0]\n",
    "n_new = new_page.count()[0]\n",
    "converted_old_page = df2.loc[((df2['converted'] == True) & (df2['landing_page'] == 'old_page'))]\n",
    "converted_new_page = df2.loc[((df2['converted'] == True) & (df2['landing_page'] == 'new_page'))]\n",
    "n_old_converted = converted_old_page.count()[0]\n",
    "n_new_converted = converted_new_page.count()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Compute test statistic and p-value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z-score: 1.951784263281866\n",
      "p_value: 0.05096382340005697\n",
      "0.9745180882999716\n",
      "1.959963984540054\n"
     ]
    }
   ],
   "source": [
    "count = np.array([n_old_converted, n_new_converted])\n",
    "nobs = np.array([n_old, n_new])\n",
    "value = .05\n",
    "z_score, p_value = sm.stats.proportion.proportions_ztest(count, nobs, alternative='two-sided', prop_var=value)\n",
    "print(\"z-score: \" + str(z_score))\n",
    "print(\"p_value: \" + str(p_value))\n",
    "\n",
    "print(norm.cdf(z_score))\n",
    "# 0.9745180882999716 # Tells us how significant our z-score is\n",
    "\n",
    "print(norm.ppf(1-(0.05/2)))\n",
    "# 1.959963984540054 # Tells us what our critical value at 95% confidence is"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Since the z-score of 1.951784263281866 does not exceed the value of 1.959963984540054, we fail to reject the null hypothesis that the difference between the two proportions is no different from zero.**\n",
    "\n",
    "**The new landing page is not statistically different and better than the old landing page. This agrees with our finding in k.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='regression'></a>\n",
    "### Part III - Logistic regression \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We will be using Logistic Regression.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11959708724499628\n",
      "0.5000619442226688\n"
     ]
    }
   ],
   "source": [
    "df2['ab_page'] = pd.get_dummies(df2['group'])['treatment']\n",
    "df2[['doesnt_convert', 'converts']] = pd.get_dummies(df2['converted'])\n",
    "df2 = df2.drop('doesnt_convert', axis=1)\n",
    "df2['intercept'] = 1\n",
    "print(df2['converts'].mean())\n",
    "print(df2['ab_page'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 448.424145\n",
      "         Iterations 6\n"
     ]
    }
   ],
   "source": [
    "# Use statsmodels to import the regression model\n",
    "log_mod = sm.api.Logit(df2['converts'], df2[['intercept', 'ab_page']])\n",
    "results = log_mod.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michellepetersen/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:488: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
      "  'available', HessianInversionWarning)\n",
      "/Users/michellepetersen/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:488: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
      "  'available', HessianInversionWarning)\n",
      "/Users/michellepetersen/anaconda3/lib/python3.6/site-packages/statsmodels/discrete/discrete_model.py:3313: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  return 1 - self.llf/self.llnull\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>     <td>converts</td>     <th>  No. Observations:  </th>   <td>290584</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>               <td>Logit</td>      <th>  Df Residuals:      </th>   <td>290582</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>               <td>MLE</td>       <th>  Df Model:          </th>   <td>     1</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>          <td>Thu, 24 Jan 2019</td> <th>  Pseudo R-squ.:     </th>   <td>   inf</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>              <td>16:59:36</td>     <th>  Log-Likelihood:    </th> <td>-1.3030e+08</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>           <td>True</td>       <th>  LL-Null:           </th>  <td>  0.0000</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th> </th>                      <td> </td>        <th>  LLR p-value:       </th>   <td> 1.000</td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>intercept</th> <td>   -1.9888</td> <td>    0.008</td> <td> -246.669</td> <td> 0.000</td> <td>   -2.005</td> <td>   -1.973</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ab_page</th>   <td>   -0.0150</td> <td>    0.011</td> <td>   -1.311</td> <td> 0.190</td> <td>   -0.037</td> <td>    0.007</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:               converts   No. Observations:               290584\n",
       "Model:                          Logit   Df Residuals:                   290582\n",
       "Method:                           MLE   Df Model:                            1\n",
       "Date:                Thu, 24 Jan 2019   Pseudo R-squ.:                     inf\n",
       "Time:                        16:59:36   Log-Likelihood:            -1.3030e+08\n",
       "converged:                       True   LL-Null:                        0.0000\n",
       "                                        LLR p-value:                     1.000\n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "intercept     -1.9888      0.008   -246.669      0.000      -2.005      -1.973\n",
       "ab_page       -0.0150      0.011     -1.311      0.190      -0.037       0.007\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9851119396030626\n",
      "1.015113064615719\n"
     ]
    }
   ],
   "source": [
    "print(np.exp(-0.0150))\n",
    "print(1/np.exp(-0.0150))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**It is a good idea to add other factors to a regression model to determine if there are multiple influences on the the AB test result.  A potential disadvantage is multicollinearity - independent variables in a regression model are correlated. A goal of regression analysis is to isoloate the relationships between each independent variable. One solution is to calculate the VIFs for each variable in the model to determine if they are correlated. If one or more of the independent variables are correlated we can remove them from the model and recompute.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "US    203619\n",
       "UK     72466\n",
       "CA     14499\n",
       "Name: country, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countries_df = pd.read_csv('./countries.csv')\n",
    "df2_new = countries_df.set_index('user_id').join(df2.set_index('user_id'), how='inner')\n",
    "df2_new['country'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>group</th>\n",
       "      <th>landing_page</th>\n",
       "      <th>converted</th>\n",
       "      <th>ab_page</th>\n",
       "      <th>converts</th>\n",
       "      <th>intercept</th>\n",
       "      <th>UK</th>\n",
       "      <th>US</th>\n",
       "      <th>CA</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>834778</th>\n",
       "      <td>UK</td>\n",
       "      <td>2017-01-14 23:08:43.304998</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>928468</th>\n",
       "      <td>US</td>\n",
       "      <td>2017-01-23 14:44:16.387854</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>822059</th>\n",
       "      <td>UK</td>\n",
       "      <td>2017-01-16 14:04:14.719771</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>711597</th>\n",
       "      <td>UK</td>\n",
       "      <td>2017-01-22 03:14:24.763511</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>710616</th>\n",
       "      <td>UK</td>\n",
       "      <td>2017-01-16 13:14:44.000513</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        country                   timestamp      group landing_page  \\\n",
       "user_id                                                               \n",
       "834778       UK  2017-01-14 23:08:43.304998    control     old_page   \n",
       "928468       US  2017-01-23 14:44:16.387854  treatment     new_page   \n",
       "822059       UK  2017-01-16 14:04:14.719771  treatment     new_page   \n",
       "711597       UK  2017-01-22 03:14:24.763511    control     old_page   \n",
       "710616       UK  2017-01-16 13:14:44.000513  treatment     new_page   \n",
       "\n",
       "         converted  ab_page  converts  intercept  UK  US  CA  \n",
       "user_id                                                       \n",
       "834778           0        0         0          1   0   1   0  \n",
       "928468           0        1         0          1   0   0   1  \n",
       "822059           1        1         1          1   0   1   0  \n",
       "711597           0        0         0          1   0   1   0  \n",
       "710616           0        1         0          1   0   1   0  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the necessary dummy variables\n",
    "df2_new[['UK', 'US', 'CA']] = pd.get_dummies(df2_new['country'])\n",
    "df2_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.366113\n",
      "         Iterations 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>     <td>converted</td>    <th>  No. Observations:  </th>   <td>290584</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>               <td>Logit</td>      <th>  Df Residuals:      </th>   <td>290580</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>               <td>MLE</td>       <th>  Df Model:          </th>   <td>     3</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>          <td>Thu, 24 Jan 2019</td> <th>  Pseudo R-squ.:     </th>  <td>2.323e-05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>              <td>16:59:37</td>     <th>  Log-Likelihood:    </th> <td>-1.0639e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>           <td>True</td>       <th>  LL-Null:           </th> <td>-1.0639e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th> </th>                      <td> </td>        <th>  LLR p-value:       </th>   <td>0.1760</td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>intercept</th> <td>   -1.9794</td> <td>    0.013</td> <td> -155.415</td> <td> 0.000</td> <td>   -2.004</td> <td>   -1.954</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ab_page</th>   <td>   -0.0149</td> <td>    0.011</td> <td>   -1.307</td> <td> 0.191</td> <td>   -0.037</td> <td>    0.007</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>UK</th>        <td>   -0.0506</td> <td>    0.028</td> <td>   -1.784</td> <td> 0.074</td> <td>   -0.106</td> <td>    0.005</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>CA</th>        <td>   -0.0099</td> <td>    0.013</td> <td>   -0.743</td> <td> 0.457</td> <td>   -0.036</td> <td>    0.016</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:              converted   No. Observations:               290584\n",
       "Model:                          Logit   Df Residuals:                   290580\n",
       "Method:                           MLE   Df Model:                            3\n",
       "Date:                Thu, 24 Jan 2019   Pseudo R-squ.:               2.323e-05\n",
       "Time:                        16:59:37   Log-Likelihood:            -1.0639e+05\n",
       "converged:                       True   LL-Null:                   -1.0639e+05\n",
       "                                        LLR p-value:                    0.1760\n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "intercept     -1.9794      0.013   -155.415      0.000      -2.004      -1.954\n",
       "ab_page       -0.0149      0.011     -1.307      0.191      -0.037       0.007\n",
       "UK            -0.0506      0.028     -1.784      0.074      -0.106       0.005\n",
       "CA            -0.0099      0.013     -0.743      0.457      -0.036       0.016\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Fit the Linear Model And Obtain the Results\n",
    "df2_new['intercept'] = 1\n",
    "\n",
    "log_mod = sm.api.Logit(df2_new['converted'], df2_new[['intercept', 'ab_page', 'UK', 'CA']])\n",
    "results = log_mod.fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "intercept    0.138154\n",
       "ab_page      0.985168\n",
       "UK           0.950621\n",
       "CA           0.990165\n",
       "dtype: float64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(results.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "intercept    7.238314\n",
       "ab_page      1.015056\n",
       "UK           1.051944\n",
       "CA           1.009932\n",
       "dtype: float64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1/np.exp(results.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "country\n",
       "CA    0.115318\n",
       "UK    0.120594\n",
       "US    0.119547\n",
       "Name: converted, dtype: float64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2_new.groupby('country').mean()['converted']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='conclusions'></a>\n",
    "## Conclusion\n",
    "\n",
    "If a user was in the US they were 1.05 more likely to convert than if they were from the UK. If a user was in the US they are 1.01 times more likely to convert than if they were in CA. US users are slightly more likely to convert."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
